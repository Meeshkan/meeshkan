---
title: How we calculate our confidence score
description: Unpacking the number that gives project managers peace of mind.
slug: how-we-calculate-our-confidence-score
date: 2020-12-14
authors: ['mike']
published: true
tags:
  - statistics
  - testing
---

[Meeshkan](https://app.meeshkan.com) exists to give Project Managers confidence that they're shipping the best possible release to their user bsae. The most important element of this confidence is our **Confidence Score**. It is a single number, from 0 to 100, that acts as a stoplight for release management.

- :green: Over 90% means that you can be highly confident you're shipping a quality release.
- :yellow: 70%-90% means that your release has several changes, defects, and untested areas that, if possible, you should address before shipping.
- :red: Under 70% means that you should seriously consider delaying your release to address some fundamental issues.

Let's unpack how the confidence score is calculated. While confidence in software may vary, we want _all_ of our users to be 100% confident in our methodology!

## Test results

40% of our confidence score is created by automated tests run by Meeshkan. These tests simulate real user behavior and are created by analyzing millions of data points from your production environment. Each test has a _status_ and a _priority_.

### Status

A test status can be:

- Passing
- Did not run
- Failing

### Priority

A test priority can be:

- Low
- Warning
- Blocking

### Creating a number

The following table shows how we attribute a number between 0 and 1 to each combination of status and priority. We then take an average of these scores for every test, which amounts to 40% of the total confidence score (higher is better).

| Score | Priority | Status      |
| ----- | -------- | ----------- |
| 0.0!  | Blocking | Failed      |
| 0.0   | Blocking | Did not run |
| 1.0   | Blocking | Passing     |
| 0.0   | Warning  | Failed      |
| 0.5   | Warning  | Did not run |
| 1.0   | Warning  | Passing     |
| 0.5   | Low      | Failed      |
| 0.5   | Low      | Did not run |
| 1.0   | Low      | Passing     |

Note that a blocking test that fails triggers a 0% confidence score for the _entire score_. We take blocking tests seriously, and you should too! Blocking means "it is better to stick with our old software than roll out something new", and while it is painful to delay a release by a few hours or days, it is normal to have last-minute blocking issues arise.

## Test coverage

Whenever we detect a new set of interactions through your application, we'll notify you to verify the interactions as expected/acceptable behavior. Then, we'll turn this set of interactions into a series of tests.

As the number of untested cases accumulate, your test coverage score will go down. The good news is that, in order to improve this aspect of the score, all you need to do is accept or reject propositions for test cases on the Meeshkan dashboard.

On the whole, test coverage represents 40% of the total confidence score.

## Difference between environments

Ideally, each release introduces a small and manageable feature set to a product. We know that, in the real world, this is not always possible. Sometimes, a release will have significant changes, creating entirely different testing results between the production and staging environment.

The last part of our score, which is 20% of the total, accounts for these differences. A high score means that there is virtually no difference in results between environments, whereas a low score means that the two environments are unrecognizably different.

## What's your confidence score?

We aim to make our confidence score as transparent, understandable and useful as possible. At the end of the day, we know you'll be using it to make quick judgements that potentially effect thousands of users. We know how valuable a great numeric metric can be: the Lighthouse Score, Net Promoter Score, and most recently the Nextjs Real Experience Score are all industry standards that impact decision making accross entire organizations. While all of these metrics are imperfect approximations, they have proven to be immensely useful in helping companies make quick and informed decisions.

Our ambition is for the Meeshkan Confidence Score to have the same attractiveness for Product Managers. As you get used to reviewing this score and attending to its various components, we're confident that the quality of your product will rise.

The best way to get started is to sign up for [Meeshkan](https://app.meeshkan.com). Signing up is free, and your first Confidence Score will be calculated within hours of registering for the service. We're looking forward to helping you ship amazing new features and services to your clients!
